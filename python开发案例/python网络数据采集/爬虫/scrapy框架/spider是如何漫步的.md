## spider
spider是定义如何刮取特定站点(或一组站点)的类，包括如何执行爬网（即跟踪链接）以及如何从页面中提取结构化数据（即scraping items）。

换句话说，Spiders是您定义用于特定站点（或某些情况下，一组站点）的爬网和解析页面的自定义行为的位置

对于spider来说，这个爬取周期是这样的：
```angularhtml
1. 您首先生成初始请求来爬取第一个URL，并指定一个回调函数，使用从这些请求下载的响应进行调用。
   第一个要执行的请求是通过调用 start_requests()（默认情况下）生成的方法，该方法为Request在start_urls该 parse方法中指定的URL 作为请求的回调函数。
2. 在回调函数中，您将解析响应（网页），并使用提取的数据，Item对象， Request对象或这些对象的可迭代返回任何一个。那些请求也将包含一个回调（可能是相同的），然后将被Scrapy下载，然后他们的响应由指定的回调处理。
3. 在回调函数中，您通常使用选择器来解析页面内容 （但您也可以使用BeautifulSoup，lxml或任何您喜欢的任何机制），并生成具有解析数据的项目。
4. 最后，从蜘蛛返回的项目通常会持续到数据库（在某些项目管道中），或者使用Feed导出将其写入文件。
```
尽管这个周期适用于（或多或少）任何一种蜘蛛，但是为了不同的目的，有各种各样的默认蜘蛛捆绑到Scrapy中。